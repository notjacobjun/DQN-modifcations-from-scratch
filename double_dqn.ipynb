{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state      = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class DDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(DDQN, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2D(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.feature_size(), 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        # reshaping the x tensor after passing through the features NN \n",
    "        x = x.view(x.size(), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "    def feature_size(self):\n",
    "        return self.features(autograd.Variable(torch.zeros(1, *self.input_shape))).view(1, -1).size(1)\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        # find the random number so that we can use e-greedy exploration\n",
    "        if random.random() > epsilon:\n",
    "            state   = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "            q_value = self.forward(state)\n",
    "            action  = q_value.max(1)[1].data[0]\n",
    "        else:\n",
    "            action = random.randrange(env.action_space.n)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define a function to update the target network periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def update_target(current_model, target_model):\n",
    "    target_model.load_state_dict(current_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "update_target(current_model, target_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initialize all the vars needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "current_model = CnnDQN(env.observation_space.shape, env.action_space.n)\n",
    "target_model  = CnnDQN(env.observation_space.shape, env.action_space.n)\n",
    "\n",
    "if USE_CUDA:\n",
    "    current_model = current_model.cuda()\n",
    "    target_model  = target_model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(current_model.parameters(), lr=0.0001)\n",
    "\n",
    "replay_initial = 10000\n",
    "replay_buffer = ReplayBuffer(100000)\n",
    "\n",
    "update_target(current_model, target_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compute the TD Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    # convert all the vars into tensor representations\n",
    "    state      = Variable(torch.FloatTensor(np.float32(state)))\n",
    "    next_state = Variable(torch.FloatTensor(np.float32(next_state)))\n",
    "    action     = Variable(torch.LongTensor(action))\n",
    "    reward     = Variable(torch.FloatTensor(reward))\n",
    "    done       = Variable(torch.FloatTensor(done))\n",
    "\n",
    "    # get the q values \n",
    "    q_values = current_model(state)\n",
    "    next_q_values = current_model(next_state)\n",
    "    next_q_state_qvalues = target_model(next_state)\n",
    "\n",
    "    q_value = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    next_q_value = next_q_values.gather(1, torch.max(next_q_values, 1)[1].unsqueeze(1)).squeeze(1)\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Start the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from common.wrappers import make_atari, wrap_deepmind, wrap_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "env_id = \"PongNoFrameskip-v4\"\n",
    "env    = make_atari(env_id)\n",
    "env    = wrap_deepmind(env)\n",
    "env    = wrap_pytorch(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mRunning cells with 'Python 3.8.2 ('reinforcement_learning': venv)' requires ipykernel package.\n",
      "\u001B[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001B[1;31mCommand: '\"/Users/jacobjun/Python projects/Lunar_Lander/reinforcement_learning/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 30000\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot([epsilon_by_frame(i) for i in range(1000000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_frames = 1000000\n",
    "batch_size = 32\n",
    "gamma      = 0.99\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state = env.reset()\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "    action = current_model.act(state, epsilon)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        \n",
    "    if len(replay_buffer) > replay_initial:\n",
    "        loss = compute_td_loss(batch_size)\n",
    "        losses.append(loss.data[0])\n",
    "        \n",
    "    if frame_idx % 10000 == 0:\n",
    "        plot(frame_idx, all_rewards, losses)\n",
    "        \n",
    "    if frame_idx % 1000 == 0:\n",
    "        update_target(current_model, target_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "444e054df59c75cf35a3ce3c9807b4242f0ba18f08834ba5e1e088781c2ff431"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}